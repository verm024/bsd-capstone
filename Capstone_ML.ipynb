{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/verm024/bsd-capstone/blob/main/Capstone_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE2wTz_RYKMU"
      },
      "source": [
        "**Code Steps**\n",
        "<br>\n",
        "\n",
        "1.   Import dataset from spreadsheet URL as csv \n",
        "2.   Split the data into training, validation, and test data\n",
        "3.   Convert the data to input pipeline using tf.data\n",
        "4.   Extract feature columns\n",
        "5.   Create the architecture of the model\n",
        "6.   Train, validate, and test the model\n",
        "7.   Export the model to TFX format\n",
        "8.   Deploy and test the deployed model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHefR0K1ZJ76"
      },
      "source": [
        "## Import Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDz35Bk8YB8p"
      },
      "source": [
        "# Import\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import feature_column\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHoGojr-ZPYR"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "r10hx-vVfAvR",
        "outputId": "b673e60a-e4d8-4561-cb36-130b00072809"
      },
      "source": [
        "# Load Dataset CSV\n",
        "URL = 'https://docs.google.com/spreadsheets/d/1h6TldA5tUq2Vu0wHfAzHqmtSkpKHHyL6ONOaf8F4PII/export?gid=0&format=csv'\n",
        "df = pd.read_csv(URL)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>umur</th>\n",
              "      <th>gaji</th>\n",
              "      <th>tanggungan</th>\n",
              "      <th>pekerjaan</th>\n",
              "      <th>diterima</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>45</td>\n",
              "      <td>1.5</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>2.5</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>42</td>\n",
              "      <td>1.6</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>63</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>47</td>\n",
              "      <td>2.7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>58</td>\n",
              "      <td>5.7</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>34</td>\n",
              "      <td>2.1</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>19</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>28</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    umur  gaji  tanggungan  pekerjaan  diterima\n",
              "0     45   1.5           5          8         1\n",
              "1     50   2.5           6          5         1\n",
              "2     60   0.0           1          0         1\n",
              "3     42   1.6           3          5         1\n",
              "4     63   0.2           0          1         1\n",
              "..   ...   ...         ...        ...       ...\n",
              "57    47   2.7           1          2         0\n",
              "58    58   5.7           2         10         0\n",
              "59    34   2.1           3          9         0\n",
              "60    19   0.2           0          4         0\n",
              "61    28   2.0           1          2         0\n",
              "\n",
              "[62 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF1BddcoZTrR"
      },
      "source": [
        "## Split Train, Validation, Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4y7zDjHSyM5",
        "outputId": "48e93d82-6b5d-4d50-c32c-6bf1a73a89b4"
      },
      "source": [
        "train, test = train_test_split(df, test_size=0.2)\n",
        "train, val = train_test_split(train, test_size=0.2)\n",
        "print(len(train), 'train examples')\n",
        "print(len(val), 'validation examples')\n",
        "print(len(test), 'test examples')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39 train examples\n",
            "10 validation examples\n",
            "13 test examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HydFhjZLZXMZ"
      },
      "source": [
        "## Convert dataframe to tf.data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOOy75CeTMWA"
      },
      "source": [
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "  dataframe = dataframe.copy()\n",
        "  labels = dataframe.pop('diterima')\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXcIDC-WTNWo",
        "outputId": "e83d3423-a0f6-41b6-b962-aa71c7d6bd4f"
      },
      "source": [
        "batch_size = 5 # A small batch sized is used for demonstration purposes\n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)\n",
        "print(train_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BatchDataset shapes: ({umur: (None,), gaji: (None,), tanggungan: (None,), pekerjaan: (None,)}, (None,)), types: ({umur: tf.int64, gaji: tf.float64, tanggungan: tf.int64, pekerjaan: tf.int64}, tf.int64)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DSFxLp9Zs1h",
        "outputId": "23427132-b2ba-48f4-ed68-786fa538a514"
      },
      "source": [
        "for feature_batch, label_batch in train_ds.take(1):\n",
        "  print('Every feature:', list(feature_batch.keys()))\n",
        "  print('A batch of ages:', feature_batch['umur'])\n",
        "  print('A batch of targets:', label_batch )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Every feature: ['umur', 'gaji', 'tanggungan', 'pekerjaan']\n",
            "A batch of ages: tf.Tensor([20 56 66 26 38], shape=(5,), dtype=int64)\n",
            "A batch of targets: tf.Tensor([0 0 1 0 0], shape=(5,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFvBSxuwZf3w"
      },
      "source": [
        "## Extract Feature Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxLbZ1AlaA-6"
      },
      "source": [
        "example_batch = next(iter(train_ds))[0]\n",
        "\n",
        "def demo(feature_column):\n",
        "  feature_layer = layers.DenseFeatures(feature_column)\n",
        "  print(feature_layer(example_batch).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkKYwlgAaOTR",
        "outputId": "34aba4f0-1a34-433c-8733-1a8f6db0db24"
      },
      "source": [
        "umur = feature_column.numeric_column(\"umur\")\n",
        "demo(umur)\n",
        "umur_buckets = feature_column.bucketized_column(umur, boundaries=[25, 35, 45, 55, 65])\n",
        "demo(umur_buckets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[51.]\n",
            " [47.]\n",
            " [29.]\n",
            " [66.]\n",
            " [41.]]\n",
            "[[0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TWkC3qicC5l",
        "outputId": "032b6bd4-8df9-4569-8cee-33b27e823111"
      },
      "source": [
        "# 0\tTidak Bekerja\n",
        "# 1\tPensiunan\n",
        "# 2\tPNS\n",
        "# 3\tWiraswasta\n",
        "# 4\tKaryawan\n",
        "# 5\tPetani/Nelayan/Peternak\n",
        "# 6\tPegawai Pemerintah\n",
        "# 7\tPekerja kasar\n",
        "# 8\tBuruh pabrik\n",
        "# 9\tPemuka Agama\n",
        "# 10\tLainnya\n",
        "\n",
        "pekerjaan = feature_column.categorical_column_with_vocabulary_list(\n",
        "      'pekerjaan', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "\n",
        "pekerjaan_one_hot = feature_column.indicator_column(pekerjaan)\n",
        "demo(pekerjaan_one_hot)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2gssaNQcb7y"
      },
      "source": [
        "feature_columns = []\n",
        "\n",
        "# numeric cols\n",
        "for header in ['umur', 'gaji', 'tanggungan', 'pekerjaan']:\n",
        "  feature_columns.append(feature_column.numeric_column(header))\n",
        "\n",
        "# bucketized cols\n",
        "umur_buckets = feature_column.bucketized_column(umur, boundaries=[25, 35, 45, 55, 65])\n",
        "feature_columns.append(umur_buckets)\n",
        "\n",
        "# categorical cols\n",
        "pekerjaan = feature_column.categorical_column_with_vocabulary_list(\n",
        "      'pekerjaan', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "\n",
        "pekerjaan_one_hot = feature_column.indicator_column(pekerjaan)\n",
        "feature_columns.append(pekerjaan_one_hot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLSpQhivfF_i"
      },
      "source": [
        "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_EgP8HJfIsn"
      },
      "source": [
        "batch_size = 32\n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGaxHXCEfJVS",
        "outputId": "5ab0799e-1423-4f51-f6e1-b3f1f2057fad"
      },
      "source": [
        "for feature_batch, label_batch in train_ds.take(1):\n",
        "  print('Every feature:', list(feature_batch.keys()))\n",
        "  print('Age:', list(feature_batch['umur']))\n",
        "  print('A batch of ages:', feature_batch['umur'])\n",
        "  print('A batch of targets:', label_batch )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Every feature: ['umur', 'gaji', 'tanggungan', 'pekerjaan']\n",
            "Age: [<tf.Tensor: shape=(), dtype=int64, numpy=38>, <tf.Tensor: shape=(), dtype=int64, numpy=28>, <tf.Tensor: shape=(), dtype=int64, numpy=66>, <tf.Tensor: shape=(), dtype=int64, numpy=55>, <tf.Tensor: shape=(), dtype=int64, numpy=34>, <tf.Tensor: shape=(), dtype=int64, numpy=36>, <tf.Tensor: shape=(), dtype=int64, numpy=33>, <tf.Tensor: shape=(), dtype=int64, numpy=45>, <tf.Tensor: shape=(), dtype=int64, numpy=63>, <tf.Tensor: shape=(), dtype=int64, numpy=57>, <tf.Tensor: shape=(), dtype=int64, numpy=60>, <tf.Tensor: shape=(), dtype=int64, numpy=20>, <tf.Tensor: shape=(), dtype=int64, numpy=36>, <tf.Tensor: shape=(), dtype=int64, numpy=65>, <tf.Tensor: shape=(), dtype=int64, numpy=26>, <tf.Tensor: shape=(), dtype=int64, numpy=26>, <tf.Tensor: shape=(), dtype=int64, numpy=63>, <tf.Tensor: shape=(), dtype=int64, numpy=65>, <tf.Tensor: shape=(), dtype=int64, numpy=42>, <tf.Tensor: shape=(), dtype=int64, numpy=60>, <tf.Tensor: shape=(), dtype=int64, numpy=47>, <tf.Tensor: shape=(), dtype=int64, numpy=50>, <tf.Tensor: shape=(), dtype=int64, numpy=63>, <tf.Tensor: shape=(), dtype=int64, numpy=47>, <tf.Tensor: shape=(), dtype=int64, numpy=78>, <tf.Tensor: shape=(), dtype=int64, numpy=35>, <tf.Tensor: shape=(), dtype=int64, numpy=48>, <tf.Tensor: shape=(), dtype=int64, numpy=59>, <tf.Tensor: shape=(), dtype=int64, numpy=57>, <tf.Tensor: shape=(), dtype=int64, numpy=45>, <tf.Tensor: shape=(), dtype=int64, numpy=21>, <tf.Tensor: shape=(), dtype=int64, numpy=26>]\n",
            "A batch of ages: tf.Tensor(\n",
            "[38 28 66 55 34 36 33 45 63 57 60 20 36 65 26 26 63 65 42 60 47 50 63 47\n",
            " 78 35 48 59 57 45 21 26], shape=(32,), dtype=int64)\n",
            "A batch of targets: tf.Tensor([0 0 1 0 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1], shape=(32,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsgJvvXDQ9MN",
        "outputId": "33bcacd2-98dd-491b-a432-917e208e9040"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  feature_layer,\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_ds,\n",
        "          validation_data=val_ds,\n",
        "          epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'umur': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=int64>, 'gaji': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'tanggungan': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=int64>, 'pekerjaan': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=int64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'umur': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=int64>, 'gaji': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'tanggungan': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=int64>, 'pekerjaan': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=int64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7444 - accuracy: 0.5000WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'umur': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=int64>, 'gaji': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'tanggungan': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=int64>, 'pekerjaan': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=int64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.7536 - accuracy: 0.4872 - val_loss: 0.6718 - val_accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.6539 - accuracy: 0.5641 - val_loss: 0.8663 - val_accuracy: 0.6000\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.8773 - accuracy: 0.5385 - val_loss: 0.6327 - val_accuracy: 0.6000\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6041 - accuracy: 0.6667 - val_loss: 0.6945 - val_accuracy: 0.4000\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8056 - accuracy: 0.4872 - val_loss: 0.6546 - val_accuracy: 0.4000\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.7390 - accuracy: 0.5641 - val_loss: 0.5867 - val_accuracy: 0.6000\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5732 - accuracy: 0.6667 - val_loss: 0.6738 - val_accuracy: 0.6000\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.6745 - accuracy: 0.5385 - val_loss: 0.6363 - val_accuracy: 0.6000\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.6244 - accuracy: 0.5897 - val_loss: 0.5284 - val_accuracy: 0.8000\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.5335 - accuracy: 0.8205 - val_loss: 0.5641 - val_accuracy: 0.7000\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.6181 - accuracy: 0.5897 - val_loss: 0.5231 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.5518 - accuracy: 0.7179 - val_loss: 0.5006 - val_accuracy: 0.7000\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.5005 - accuracy: 0.7436 - val_loss: 0.5292 - val_accuracy: 0.6000\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.5418 - accuracy: 0.6667 - val_loss: 0.4856 - val_accuracy: 0.7000\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.4807 - accuracy: 0.7692 - val_loss: 0.4589 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4776 - accuracy: 0.8205 - val_loss: 0.4785 - val_accuracy: 0.9000\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.5035 - accuracy: 0.6923 - val_loss: 0.4299 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4292 - accuracy: 0.9231 - val_loss: 0.4472 - val_accuracy: 0.7000\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.4735 - accuracy: 0.7692 - val_loss: 0.4528 - val_accuracy: 0.7000\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4786 - accuracy: 0.7436 - val_loss: 0.3912 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3972 - accuracy: 0.9231 - val_loss: 0.4032 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4385 - accuracy: 0.7436 - val_loss: 0.3956 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4301 - accuracy: 0.7692 - val_loss: 0.3527 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3738 - accuracy: 0.8974 - val_loss: 0.3935 - val_accuracy: 0.7000\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4333 - accuracy: 0.7692 - val_loss: 0.3587 - val_accuracy: 0.9000\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.3749 - accuracy: 0.8462 - val_loss: 0.3246 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.3705 - accuracy: 0.8974 - val_loss: 0.3455 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.4003 - accuracy: 0.8205 - val_loss: 0.3022 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.3212 - accuracy: 0.9487 - val_loss: 0.3309 - val_accuracy: 0.9000\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.3887 - accuracy: 0.8205 - val_loss: 0.3323 - val_accuracy: 0.8000\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3635 - accuracy: 0.8462 - val_loss: 0.2796 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3158 - accuracy: 0.9231 - val_loss: 0.3347 - val_accuracy: 0.9000\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4174 - accuracy: 0.7436 - val_loss: 0.3039 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3535 - accuracy: 0.8205 - val_loss: 0.2630 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2819 - accuracy: 0.9231 - val_loss: 0.2903 - val_accuracy: 0.9000\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3399 - accuracy: 0.8462 - val_loss: 0.2743 - val_accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3010 - accuracy: 0.9231 - val_loss: 0.2487 - val_accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.2701 - accuracy: 0.9231 - val_loss: 0.2772 - val_accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.3248 - accuracy: 0.8462 - val_loss: 0.2628 - val_accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3002 - accuracy: 0.8974 - val_loss: 0.2323 - val_accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.2602 - accuracy: 0.9231 - val_loss: 0.2290 - val_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.2497 - accuracy: 0.9487 - val_loss: 0.2224 - val_accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.2529 - accuracy: 0.9231 - val_loss: 0.2286 - val_accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.2508 - accuracy: 0.9231 - val_loss: 0.2151 - val_accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.2370 - accuracy: 0.9231 - val_loss: 0.2076 - val_accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.2247 - accuracy: 0.9487 - val_loss: 0.2034 - val_accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.2212 - accuracy: 0.9231 - val_loss: 0.1986 - val_accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.2166 - accuracy: 0.9231 - val_loss: 0.1937 - val_accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.2133 - accuracy: 0.9231 - val_loss: 0.1896 - val_accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2111 - accuracy: 0.9231 - val_loss: 0.1864 - val_accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.2071 - accuracy: 0.9231 - val_loss: 0.1814 - val_accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.2029 - accuracy: 0.9231 - val_loss: 0.1792 - val_accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.2020 - accuracy: 0.9487 - val_loss: 0.1761 - val_accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1982 - accuracy: 0.9487 - val_loss: 0.1719 - val_accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1945 - accuracy: 0.9231 - val_loss: 0.1780 - val_accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.2155 - accuracy: 0.9231 - val_loss: 0.1730 - val_accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.2072 - accuracy: 0.9231 - val_loss: 0.1602 - val_accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1853 - accuracy: 0.9231 - val_loss: 0.1784 - val_accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.2184 - accuracy: 0.9487 - val_loss: 0.1820 - val_accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.2277 - accuracy: 0.8974 - val_loss: 0.1572 - val_accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1753 - accuracy: 0.9744 - val_loss: 0.1580 - val_accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1999 - accuracy: 0.9231 - val_loss: 0.1762 - val_accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.2189 - accuracy: 0.8718 - val_loss: 0.1538 - val_accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.1725 - accuracy: 0.9231 - val_loss: 0.1433 - val_accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.1684 - accuracy: 0.9744 - val_loss: 0.1590 - val_accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.2262 - accuracy: 0.9231 - val_loss: 0.1462 - val_accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.2002 - accuracy: 0.9487 - val_loss: 0.1394 - val_accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.1596 - accuracy: 0.9231 - val_loss: 0.1480 - val_accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.1769 - accuracy: 0.9231 - val_loss: 0.1413 - val_accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.1623 - accuracy: 0.9231 - val_loss: 0.1291 - val_accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.1517 - accuracy: 0.9744 - val_loss: 0.1383 - val_accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1876 - accuracy: 0.9487 - val_loss: 0.1342 - val_accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.1781 - accuracy: 0.9487 - val_loss: 0.1232 - val_accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1504 - accuracy: 0.9744 - val_loss: 0.1257 - val_accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.1504 - accuracy: 0.9231 - val_loss: 0.1219 - val_accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.1453 - accuracy: 0.9231 - val_loss: 0.1186 - val_accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.1434 - accuracy: 0.9744 - val_loss: 0.1210 - val_accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1515 - accuracy: 0.9744 - val_loss: 0.1219 - val_accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.1575 - accuracy: 0.9487 - val_loss: 0.1152 - val_accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1390 - accuracy: 0.9744 - val_loss: 0.1180 - val_accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1505 - accuracy: 0.9231 - val_loss: 0.1268 - val_accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1532 - accuracy: 0.9231 - val_loss: 0.1122 - val_accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1268 - accuracy: 0.9744 - val_loss: 0.1133 - val_accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1609 - accuracy: 0.9487 - val_loss: 0.1219 - val_accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1928 - accuracy: 0.9487 - val_loss: 0.1078 - val_accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1377 - accuracy: 0.9487 - val_loss: 0.1209 - val_accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1385 - accuracy: 0.9231 - val_loss: 0.1623 - val_accuracy: 0.9000\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.1878 - accuracy: 0.9231 - val_loss: 0.1436 - val_accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1588 - accuracy: 0.9487 - val_loss: 0.1061 - val_accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1225 - accuracy: 0.9744 - val_loss: 0.1039 - val_accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1422 - accuracy: 0.9487 - val_loss: 0.1114 - val_accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1643 - accuracy: 0.9487 - val_loss: 0.1041 - val_accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1405 - accuracy: 0.9487 - val_loss: 0.0973 - val_accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.1157 - accuracy: 0.9744 - val_loss: 0.1099 - val_accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1319 - accuracy: 0.9231 - val_loss: 0.1214 - val_accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.1485 - accuracy: 0.9487 - val_loss: 0.1115 - val_accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.1322 - accuracy: 0.9231 - val_loss: 0.0954 - val_accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1222 - accuracy: 0.9744 - val_loss: 0.0922 - val_accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1155 - accuracy: 0.9744 - val_loss: 0.0914 - val_accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1127 - accuracy: 0.9744 - val_loss: 0.0913 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fda461a94d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsIASYZDREOh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07418afa-256f-4be4-a262-d295ad367f90"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print(\"Test Accuracy\", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3174 - accuracy: 0.8462\n",
            "Accuracy 0.8461538553237915\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK-I5scqBQRr"
      },
      "source": [
        "## Tensorflow Serving\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MkCcrFqBZLr",
        "outputId": "e693d54a-cf28-4388-cd06-0a8d17061485"
      },
      "source": [
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update\n",
        "!apt-get install tensorflow-model-server"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2943  100  2943    0     0  81750      0 --:--:-- --:--:-- --:--:-- 81750\n",
            "OK\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,012 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Get:7 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 Packages [340 B]\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server-universal amd64 Packages [347 B]\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:12 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:14 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [60.9 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Ign:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [798 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [423 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,152 kB]\n",
            "Hit:20 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,413 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,184 kB]\n",
            "Hit:23 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:24 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:25 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,769 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,584 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [452 kB]\n",
            "Get:28 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [905 kB]\n",
            "Get:29 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [41.5 kB]\n",
            "Fetched 13.1 MB in 4s (3,131 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "80 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  tensorflow-model-server\n",
            "0 upgraded, 1 newly installed, 0 to remove and 80 not upgraded.\n",
            "Need to get 326 MB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 tensorflow-model-server all 2.5.1 [326 MB]\n",
            "Fetched 326 MB in 5s (68.7 MB/s)\n",
            "Selecting previously unselected package tensorflow-model-server.\n",
            "(Reading database ... 160706 files and directories currently installed.)\n",
            "Preparing to unpack .../tensorflow-model-server_2.5.1_all.deb ...\n",
            "Unpacking tensorflow-model-server (2.5.1) ...\n",
            "Setting up tensorflow-model-server (2.5.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QaGAbHAAG4v"
      },
      "source": [
        "## Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a1498Y2dfoe",
        "outputId": "adb69b74-0726-461a-e902-7cfa521b1986"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "id": "K3IllEblAMKC",
        "outputId": "25535c7f-381c-4f8c-e753-4c19dc8eccab"
      },
      "source": [
        "import os\n",
        "import tempfile\n",
        "\n",
        "MODEL_DIR = tempfile.gettempdir() # MODEL_DIR='/tmp'\n",
        "# MODEL_DIR = \"/content/drive/MyDrive/Capstone/Model\"\n",
        "version = 1\n",
        "\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "\n",
        "if os.path.isdir(export_path):\n",
        "    print('\\nAlready saved a model, cleaning up\\n')\n",
        "    !rm -r {export_path}\n",
        "\n",
        "model.save(export_path, save_format=\"tf\")\n",
        "\n",
        "print('\\nexport_path = {}'.format(export_path))\n",
        "!ls -l {export_path}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Already saved a model, cleaning up\n",
            "\n",
            "rm: cannot remove '/content/drive/MyDrive/Capstone/Model/1/variables/variables.data-00000-of-00001': Operation not permitted\n",
            "rm: cannot remove '/content/drive/MyDrive/Capstone/Model/1/variables/variables.index': Operation not permitted\n",
            "rm: cannot remove '/content/drive/MyDrive/Capstone/Model/1/assets': Operation not permitted\n",
            "rm: cannot remove '/content/drive/MyDrive/Capstone/Model/1/keras_metadata.pb': Operation not permitted\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'umur': <tf.Tensor 'umur:0' shape=(None, 1) dtype=int64>, 'gaji': <tf.Tensor 'gaji:0' shape=(None, 1) dtype=float64>, 'tanggungan': <tf.Tensor 'tanggungan:0' shape=(None, 1) dtype=int64>, 'pekerjaan': <tf.Tensor 'pekerjaan:0' shape=(None, 1) dtype=int64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'umur': <tf.Tensor 'inputs_3:0' shape=(None, 1) dtype=int64>, 'gaji': <tf.Tensor 'inputs:0' shape=(None, 1) dtype=float64>, 'tanggungan': <tf.Tensor 'inputs_2:0' shape=(None, 1) dtype=int64>, 'pekerjaan': <tf.Tensor 'inputs_1:0' shape=(None, 1) dtype=int64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'umur': <tf.Tensor 'inputs_3:0' shape=(None, 1) dtype=int64>, 'gaji': <tf.Tensor 'inputs:0' shape=(None, 1) dtype=float64>, 'tanggungan': <tf.Tensor 'inputs_2:0' shape=(None, 1) dtype=int64>, 'pekerjaan': <tf.Tensor 'inputs_1:0' shape=(None, 1) dtype=int64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'umur': <tf.Tensor 'umur:0' shape=(None, 1) dtype=int64>, 'gaji': <tf.Tensor 'gaji:0' shape=(None, 1) dtype=float64>, 'tanggungan': <tf.Tensor 'tanggungan:0' shape=(None, 1) dtype=int64>, 'pekerjaan': <tf.Tensor 'pekerjaan:0' shape=(None, 1) dtype=int64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'umur': <tf.Tensor 'umur:0' shape=(None, 1) dtype=int64>, 'gaji': <tf.Tensor 'gaji:0' shape=(None, 1) dtype=float64>, 'tanggungan': <tf.Tensor 'tanggungan:0' shape=(None, 1) dtype=int64>, 'pekerjaan': <tf.Tensor 'pekerjaan:0' shape=(None, 1) dtype=int64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'umur': <tf.Tensor 'inputs/umur:0' shape=(None, 1) dtype=int64>, 'gaji': <tf.Tensor 'inputs/gaji:0' shape=(None, 1) dtype=float64>, 'tanggungan': <tf.Tensor 'inputs/tanggungan:0' shape=(None, 1) dtype=int64>, 'pekerjaan': <tf.Tensor 'inputs/pekerjaan:0' shape=(None, 1) dtype=int64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'umur': <tf.Tensor 'inputs/umur:0' shape=(None, 1) dtype=int64>, 'gaji': <tf.Tensor 'inputs/gaji:0' shape=(None, 1) dtype=float64>, 'tanggungan': <tf.Tensor 'inputs/tanggungan:0' shape=(None, 1) dtype=int64>, 'pekerjaan': <tf.Tensor 'inputs/pekerjaan:0' shape=(None, 1) dtype=int64>}\n",
            "Consider rewriting this model with the Functional API.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "PermissionDeniedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-1cab8be6f2e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm -r {export_path}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nexport_path = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m   2110\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2111\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 2112\u001b[0;31m                     signatures, options, save_traces)\n\u001b[0m\u001b[1;32m   2113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m   def save_weights(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSharedObjectSavingScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m       saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0;32m--> 151\u001b[0;31m                             signatures, options, save_traces)\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_option_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_traces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m       saved_nodes, node_paths = save_lib.save_and_return_nodes(\n\u001b[0;32m---> 90\u001b[0;31m           model, filepath, signatures, options)\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# Save all metadata to a separate file in the SavedModel directory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, raise_metadata_warning, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1112\u001b[0m         experimental_io_device=options.experimental_io_device)\n\u001b[1;32m   1113\u001b[0m     object_saver.save(\n\u001b[0;32m-> 1114\u001b[0;31m         utils_impl.get_variables_path(export_dir), options=ckpt_options)\n\u001b[0m\u001b[1;32m   1115\u001b[0m     builder_impl.copy_assets_to_destination_dir(asset_info.asset_filename_map,\n\u001b[1;32m   1116\u001b[0m                                                 export_dir)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, checkpoint_number, session, options)\u001b[0m\n\u001b[1;32m   1217\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m     save_path, new_feed_additions = self._save_cached_when_graph_building(\n\u001b[0;32m-> 1219\u001b[0;31m         file_prefix_tensor, object_graph_tensor, options)\n\u001b[0m\u001b[1;32m   1220\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnew_feed_additions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m       \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_feed_additions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36m_save_cached_when_graph_building\u001b[0;34m(self, file_prefix, object_graph_tensor, options)\u001b[0m\n\u001b[1;32m   1162\u001b[0m         or context.executing_eagerly() or ops.inside_function()):\n\u001b[1;32m   1163\u001b[0m       \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiDeviceSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamed_saveable_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m       \u001b[0msave_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msave_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0mtf_function_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msave_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    272\u001b[0m           \u001b[0;31m# initial read operations should be placed on the SaveableObject's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m           \u001b[0;31m# device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m           \u001b[0msharded_saves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msharded_saves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0msave_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_io_device\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"cpu:0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mio_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2\u001b[0;34m(prefix, tensor_names, shape_and_slices, tensors, name)\u001b[0m\n\u001b[1;32m   1696\u001b[0m       return save_v2_eager_fallback(\n\u001b[1;32m   1697\u001b[0m           \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_and_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1698\u001b[0;31m           ctx=_ctx)\n\u001b[0m\u001b[1;32m   1699\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1700\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2_eager_fallback\u001b[0;34m(prefix, tensor_names, shape_and_slices, tensors, name, ctx)\u001b[0m\n\u001b[1;32m   1716\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"dtypes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_dtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1717\u001b[0m   _result = _execute.execute(b\"SaveV2\", 0, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 1718\u001b[0;31m                              ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m   1719\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1720\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPermissionDeniedError\u001b[0m: /content/drive/MyDrive/Capstone/Model/1/variables/variables_temp; Read-only file system [Op:SaveV2]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2qIzRyGAY5g",
        "outputId": "b841312a-da39-4e70-befe-6f5ea62c19bf"
      },
      "source": [
        "!saved_model_cli show --dir {export_path} --all"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['gaji'] tensor_info:\n",
            "        dtype: DT_DOUBLE\n",
            "        shape: (-1, 1)\n",
            "        name: serving_default_gaji:0\n",
            "    inputs['pekerjaan'] tensor_info:\n",
            "        dtype: DT_INT64\n",
            "        shape: (-1, 1)\n",
            "        name: serving_default_pekerjaan:0\n",
            "    inputs['tanggungan'] tensor_info:\n",
            "        dtype: DT_INT64\n",
            "        shape: (-1, 1)\n",
            "        name: serving_default_tanggungan:0\n",
            "    inputs['umur'] tensor_info:\n",
            "        dtype: DT_INT64\n",
            "        shape: (-1, 1)\n",
            "        name: serving_default_umur:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['output_1'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 1)\n",
            "        name: StatefulPartitionedCall_1:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0527 11:50:53.102411 139837273036672 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "2021-05-27 11:50:53.188694: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-05-27 11:50:53.202698: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-05-27 11:50:53.202754: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fb6e5d415081): /proc/driver/nvidia/version does not exist\n",
            "2021-05-27 11:50:53.210153: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2021-05-27 11:50:53.210443: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b45c950f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-05-27 11:50:53.210480: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "\n",
            "Defined Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: dict\n",
            "          Value: {'tanggungan': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'tanggungan'), 'umur': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'umur'), 'pekerjaan': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'pekerjaan'), 'gaji': TensorSpec(shape=(None, 1), dtype=tf.float64, name=u'gaji'), \b\b}\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: dict\n",
            "          Value: {'tanggungan': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'inputs/tanggungan'), 'umur': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'inputs/umur'), 'pekerjaan': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'inputs/pekerjaan'), 'gaji': TensorSpec(shape=(None, 1), dtype=tf.float64, name=u'inputs/gaji'), \b\b}\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: dict\n",
            "          Value: {'tanggungan': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'inputs/tanggungan'), 'umur': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'inputs/umur'), 'pekerjaan': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'inputs/pekerjaan'), 'gaji': TensorSpec(shape=(None, 1), dtype=tf.float64, name=u'inputs/gaji'), \b\b}\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: dict\n",
            "          Value: {'tanggungan': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'tanggungan'), 'umur': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'umur'), 'pekerjaan': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'pekerjaan'), 'gaji': TensorSpec(shape=(None, 1), dtype=tf.float64, name=u'gaji'), \b\b}\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: dict\n",
            "          Value: {'tanggungan': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'tanggungan'), 'umur': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'umur'), 'pekerjaan': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'pekerjaan'), 'gaji': TensorSpec(shape=(None, 1), dtype=tf.float64, name=u'gaji'), \b\b}\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: dict\n",
            "          Value: {'pekerjaan': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'pekerjaan'), 'umur': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'umur'), 'tanggungan': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'tanggungan'), 'gaji': TensorSpec(shape=(None, 1), dtype=tf.float64, name=u'gaji'), \b\b}\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: dict\n",
            "          Value: {'tanggungan': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'inputs/tanggungan'), 'gaji': TensorSpec(shape=(None, 1), dtype=tf.float64, name=u'inputs/gaji'), 'pekerjaan': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'inputs/pekerjaan'), 'umur': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'inputs/umur'), \b\b}\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: dict\n",
            "          Value: {'tanggungan': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'inputs/tanggungan'), 'umur': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'inputs/umur'), 'pekerjaan': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'inputs/pekerjaan'), 'gaji': TensorSpec(shape=(None, 1), dtype=tf.float64, name=u'inputs/gaji'), \b\b}\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: dict\n",
            "          Value: {'tanggungan': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'tanggungan'), 'umur': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'umur'), 'pekerjaan': TensorSpec(shape=(None, 1), dtype=tf.int64, name=u'pekerjaan'), 'gaji': TensorSpec(shape=(None, 1), dtype=tf.float64, name=u'gaji'), \b\b}\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "W0527 11:50:53.392664 139837273036672 util.py:144] Unresolved object in checkpoint: (root).layer-0._resources.pekerjaan.pekerjaan_lookup._initializer\n",
            "W0527 11:50:53.392924 139837273036672 util.py:152] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOyXWT7jAZTn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f7e498a-01ce-4568-ebb7-a9dc279a3829"
      },
      "source": [
        "os.environ[\"MODEL_DIR\"] = MODEL_DIR\n",
        "print(MODEL_DIR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tmp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARmsAmfQBgLB"
      },
      "source": [
        "## Serve model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czCjZdCSAbsG",
        "outputId": "4a84f3be-e029-4a60-e83a-92af801f66ae"
      },
      "source": [
        "%%bash --bg \n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port=8501 \\\n",
        "  --model_name=bsd \\\n",
        "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting job # 3 in a separate thread.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCnL57LQAc6W",
        "outputId": "94a6cd73-d05d-4ef1-dce1-46bb5b3012a4"
      },
      "source": [
        "!tail server.log"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-27 11:50:58.538642: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: /tmp/1\n",
            "2021-05-27 11:50:58.549654: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 76786 microseconds.\n",
            "2021-05-27 11:50:58.551312: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /tmp/1/assets.extra/tf_serving_warmup_requests\n",
            "2021-05-27 11:50:58.551471: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: bsd version: 1}\n",
            "2021-05-27 11:50:58.552157: I tensorflow_serving/model_servers/server_core.cc:486] Finished adding/updating models\n",
            "2021-05-27 11:50:58.552227: I tensorflow_serving/model_servers/server.cc:367] Profiler service is enabled\n",
            "2021-05-27 11:50:58.552843: I tensorflow_serving/model_servers/server.cc:393] Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
            "[warn] getaddrinfo: address family for nodename not supported\n",
            "2021-05-27 11:50:58.553497: I tensorflow_serving/model_servers/server.cc:414] Exporting HTTP/REST API at:localhost:8501 ...\n",
            "[evhttp_server.cc : 245] NET_LOG: Entering the event loop ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2iYpffmBqtH"
      },
      "source": [
        "## Sample request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-jZCF5RByD8",
        "outputId": "c2702490-1f77-4b78-d9a6-62d32c069af7"
      },
      "source": [
        "import json\n",
        "import requests\n",
        "\n",
        "xs = [{\"gaji\": [test.iloc[0][1]], \"pekerjaan\": [int(test.iloc[0][3])], \"tanggungan\": [int(test.iloc[0][2])], \"umur\": [int(test.iloc[0][0])]}, {\"gaji\": [test.iloc[1][1]], \"pekerjaan\": [int(test.iloc[1][3])], \"tanggungan\": [int(test.iloc[1][2])], \"umur\": [int(test.iloc[1][0])]}]\n",
        "print(\"Data:\", xs)\n",
        "\n",
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": xs})\n",
        "\n",
        "headers = {\"content-type\": \"application/json\"}\n",
        "json_response = requests.post('http://34.101.148.92:8501/v1/models/bsd:predict', data=data, headers=headers)\n",
        "\n",
        "predictions = json.loads(json_response.text)['predictions']\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data: [{'gaji': [2.2], 'pekerjaan': [5], 'tanggungan': [4], 'umur': [57]}, {'gaji': [0.0], 'pekerjaan': [0], 'tanggungan': [1], 'umur': [65]}]\n",
            "[[0.833278537], [0.96526444]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}